{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## FACE RECOGNITION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for image scraping from webpages\n",
        "from bs4 import BeautifulSoup\n",
        "# for handling URLs\n",
        "from urllib.request import urlopen\n",
        "# for regular expression\n",
        "import re\n",
        "# for interacting with the operating system\n",
        "import os\n",
        "# for sending HTTP requests\n",
        "import requests as req\n",
        "# for reconginizing faces in a photograph or video frame\n",
        "import face_recognition\n",
        "# for video and image processing\n",
        "import cv2\n",
        "# for matching filepaths\n",
        "import glob\n",
        "# for working with arrays \n",
        "import numpy as np\n",
        "# for formatting date objects into readable strings\n",
        "import datetime\n",
        "# to copy the screen sontent to a PIL image memory\n",
        "from PIL import ImageGrab\n",
        "# to retrieve a specified system configuration settings for height and width\n",
        "from win32api import GetSystemMetrics\n",
        "# selecting random values for the colour of the text output\n",
        "from random import randrange\n",
        "\n",
        "from tkinter import Tk     \n",
        "from tkinter.filedialog import askopenfilename\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "SELECT YOUR OPTION ACCORDING TO THE TASK TO BE PERFORMED \n",
        "1. Face recognition on a Videofile / screen recording\n",
        "2. Face recognition in real time\n",
        "3. Exit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "counter = int(input())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "DO YOU WANT TO CREATE A NEW DATASET TO INCLUDE FOR ABOVE TASKS ?\n",
        "\n",
        "1. YES\n",
        "2. NO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_counter = int(input())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For adding new images to recognize just add the .jpg files to the images folder.\n",
        "I have written the code for bulk adding photos as well just add the full names of the people to add_names.txt and their images will automatically be downloaded to the images folder.\n",
        "Basically we are doing web scraping from wikipedia pages to get the images of the people.\n",
        "In this instance we have taken several academy award winners and a lot of bollywood actors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if dataset_counter == 1:\n",
        "  # giving the path of the text file to be read\n",
        "  data_file = open('add_names.txt', \"r\")\n",
        "  # reading the file line by line\n",
        "  file_content = data_file.read()\n",
        "  # replacing whitespaces with '_' \n",
        "  file_content = file_content.replace(\" \", '_')\n",
        "  # storing the contents of the text file into a list format\n",
        "  content_list = file_content.split(\"\\n\")\n",
        "  print(content_list)\n",
        "  data_file.close()\n",
        "\n",
        "  #creating a directory named images \n",
        "  try:\n",
        "    os.mkdir('images')\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  # looping through the entire list\n",
        "  for i in range(0, len(content_list)):\n",
        "      try:\n",
        "        # providing the url to be accessed\n",
        "        website_url = 'https://en.wikipedia.org/wiki/' + content_list[i]\n",
        "        htmldata = urlopen(website_url)\n",
        "        soup = BeautifulSoup(htmldata, 'html.parser')\n",
        "        # finding images from the webpage with the extension '.jpg' only\n",
        "        images = soup.find_all('img', {'src': re.compile('.jpg')})\n",
        "        # getting the first '.jpg' image available on the webpage\n",
        "        img_data = req.get('https:' + images[0]['src']).content\n",
        "        # downloading and storing the images in the images directory created earlier\n",
        "        with open('images/' + content_list[i] + '.jpg', 'wb+') as f:\n",
        "          f.write(img_data)\n",
        "      except:\n",
        "          pass\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "FOR SCREEN RECORDIDING USE SCREEN_REC.PY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_u1fA7A8Z8wb"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# # Screen Recording Part \n",
        "# if(counter == 1):\n",
        "#     print(\"Use the screen_rec.py or any other screen recording software to get the source file for face recognition \")\n",
        "#     Tk().withdraw()  # we don't want a full GUI, so keep the root window from appearing\n",
        "#     # show an \"Open\" dialog box and return the path to the selected file\n",
        "#     file_name = askopenfilename()\n",
        "#     print(file_name)\n",
        "\n",
        "#     # # getting the height and width of the screen from the system\n",
        "#     # width = GetSystemMetrics(0)\n",
        "#     # height = GetSystemMetrics(1)\n",
        "#     # #get the current time of the scren recording and convert it into a string\n",
        "#     # time_stamp = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
        "#     # # format the name of the screen recording file to be saved\n",
        "#     # screen_recording = f'{time_stamp}.mp4'\n",
        "#     # # giving characters to perform encoding operations\n",
        "#     # enc_chars = cv2.VideoWriter_enc_chars('m', 'p', '4', 'v')\n",
        "#     # vid_captured = cv2.VideoWriter(screen_recording, enc_chars, 20.0, (width, height))\n",
        "\n",
        "#     # while True:\n",
        "#     #     # grab the image from the screen\n",
        "#     #     img = ImageGrab.grab(bbox=(0, 0, width, height))\n",
        "#     #     # convert the image into a numpy array \n",
        "#     #     img_arr = np.array(img)\n",
        "#     #     #convert the colour of the image to an RGB colour\n",
        "#     #     final_img = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
        "#     #     #display the image\n",
        "#     #     cv2.imshow('Screen Recording', final_img)\n",
        "\n",
        "#     #     # write the final image captured\n",
        "#     #     vid_captured.write(final_img)\n",
        "#     #     # to stop screen recording\n",
        "#     #     if cv2.waitKey(10) == ord('q'):\n",
        "#     #         break\n",
        "#     # cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WcPnMwHetciI"
      },
      "outputs": [],
      "source": [
        "class SimpleFaceRecognition:\n",
        "    def __init__(self):\n",
        "        self.known_face_encodings = []\n",
        "        self.known_face_names = []\n",
        "\n",
        "        # Resize frame for a faster speed\n",
        "        self.frame_resizing = 0.25\n",
        "\n",
        "    def load_encoding_images(self, images_path):\n",
        "        # Load Images\n",
        "        images_path = glob.glob(os.path.join(images_path, \"*.*\"))\n",
        "\n",
        "        print(\"{} encoding images found.\".format(len(images_path)))\n",
        "\n",
        "        # Store image encoding and names\n",
        "        for img_path in images_path:\n",
        "            try:\n",
        "              img = cv2.imread(img_path)\n",
        "              rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "              # Get the filename only from the initial file path.\n",
        "              basename = os.path.basename(img_path)\n",
        "              (filename, ext) = os.path.splitext(basename)\n",
        "              # Get encoding\n",
        "              img_encoding = face_recognition.face_encodings(rgb_img)[0]\n",
        "\n",
        "              # Store file name and file encoding\n",
        "              self.known_face_encodings.append(img_encoding)\n",
        "              self.known_face_names.append(filename)\n",
        "            except:\n",
        "              pass\n",
        "        print(\"Encoding images loaded\")\n",
        "\n",
        "    def detect_known_faces(self, frame):\n",
        "        try:\n",
        "          small_frame = cv2.resize(frame, (0, 0), fx=self.frame_resizing, fy=self.frame_resizing)\n",
        "        except:\n",
        "          return\n",
        "        # Find all the faces and face encodings in the current frame of video\n",
        "        # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n",
        "        rgb_small_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)\n",
        "        face_locations = face_recognition.face_locations(rgb_small_frame)\n",
        "        face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
        "\n",
        "        face_names = []\n",
        "        for face_encoding in face_encodings:\n",
        "            # See if the face is a match for the known face(s)\n",
        "            matches = face_recognition.compare_faces(self.known_face_encodings, face_encoding)\n",
        "            name = \"Unknown\"\n",
        "\n",
        "            # Or instead, use the known face with the smallest distance to the new face\n",
        "            face_distances = face_recognition.face_distance(self.known_face_encodings, face_encoding)\n",
        "            best_match_index = np.argmin(face_distances)\n",
        "            if matches[best_match_index]:\n",
        "                name = self.known_face_names[best_match_index]\n",
        "            face_names.append(name)\n",
        "\n",
        "        # Convert to numpy array to adjust coordinates with frame resizing quickly\n",
        "        face_locations = np.array(face_locations)\n",
        "        face_locations = face_locations / self.frame_resizing\n",
        "        return face_locations.astype(int), face_names\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDTYTrE1Q6rG",
        "outputId": "f1133cf8-df04-43d3-ffdf-605fd4bd6959"
      },
      "outputs": [],
      "source": [
        "# Encode faces from a folder\n",
        "SimpleFaceRecognition_obj = SimpleFaceRecognition()\n",
        "SimpleFaceRecognition_obj.load_encoding_images(\"images/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if(counter == 1):\n",
        "    print(\"Use the screen_rec.py or any other screen recording software to get the source file for face recognition \")\n",
        "    Tk().withdraw()  # we don't need a full GUI, so we keep the root window from appearing\n",
        "    # show an \"Open\" dialog box and return the path to the selected file\n",
        "    file_name = askopenfilename()\n",
        "    print(file_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpNX2r_aZBNo",
        "outputId": "748f1fd4-04a2-4306-fa07-44ce60e64ffc"
      },
      "outputs": [],
      "source": [
        "if counter == 1:\n",
        "    cap = cv2.VideoCapture(file_name)\n",
        "    frame_width = int(cap.get(3))\n",
        "    frame_height = int(cap.get(4))\n",
        "    f = open(\"screen_rec_output.avi\", 'w')\n",
        "    f.close()\n",
        "    out = cv2.VideoWriter('screen_rec_output.avi', cv2.VideoWriter_fourcc(\n",
        "        'M', 'J', 'P', 'G'), 10, (frame_width, frame_height))\n",
        "elif counter == 2:\n",
        "    cap = cv2.VideoCapture(0)\n",
        "    frame_width = int(cap.get(3))\n",
        "    frame_height = int(cap.get(4))\n",
        "    f = open(\"real_time_output_video.avi\", 'w')\n",
        "    f.close()\n",
        "    out = cv2.VideoWriter('real_time_output_video.avi', cv2.VideoWriter_fourcc(\n",
        "        'M', 'J', 'P', 'G'), 10, (frame_width, frame_height))\n",
        "\n",
        "\n",
        "names_set = []\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    # Detect Faces\n",
        "    if(SimpleFaceRecognition_obj.detect_known_faces(frame) == None):\n",
        "      break\n",
        "    face_locations, face_names = SimpleFaceRecognition_obj.detect_known_faces(\n",
        "        frame)\n",
        "    for face_loc, name in zip(face_locations, face_names):\n",
        "        y1, x2, y2, x1 = face_loc[0], face_loc[1], face_loc[2], face_loc[3]\n",
        "        red = randrange(128, 256)\n",
        "        green = randrange(128, 256)\n",
        "        blue = randrange(128, 256)\n",
        "        cv2.putText(frame, name, (x1, y1 - 10),\n",
        "                    cv2.FONT_HERSHEY_DUPLEX, 1, (red, green, blue), 2)\n",
        "        cv2.rectangle(frame, (x1, y1), (x2, y2), (red, green, blue), 4)\n",
        "        names_set.append(name)\n",
        "        #print(name)\n",
        "\n",
        "    cv2.imshow(\"Frame\",frame)      \n",
        "    out.write(frame)\n",
        "    key = cv2.waitKey(1)\n",
        "    if key == 27:\n",
        "        break\n",
        "\n",
        "\n",
        "\n",
        "res = []\n",
        "for i in names_set:\n",
        "    if i not in res:\n",
        "        res.append(i)\n",
        "\n",
        "print(res)\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if(counter == 1 ):\n",
        "    print(\"The program has been executed successfully you face labelled file is saved as screen_rec_output.avi\")\n",
        "if(counter == 2):\n",
        "    print(\"The program has been executed successfully you face labelled file is saved as real_time_output_video.avi\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Real_Time_Face recognition.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
